{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d13301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86d8e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('story.txt', encoding=\"utf8\") as file:\n",
    "    lines = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6991997",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = lines.replace('ï¿½', ' ')\n",
    "words_list = lines.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261179a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631db61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83d8dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 70000 # max number of words to have in our vocabulary\n",
    "max_length = 40 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length,\n",
    "                                    pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ebfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee131ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9dff7d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=int64, numpy=\n",
       "array([3279, 3279, 3279, 3279,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(\"price price price price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3f5d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2eba2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79a614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0c53a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8607bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"response\"],\n",
    "                                                   data[\"number\"],\n",
    "                                                   test_size=0.2, random_state=42)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b3cfc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "### from tensorflow.keras import layers\n",
    "tf.random.set_seed(42)\n",
    "embedding = layers.Embedding(input_dim=40,\n",
    "                                     output_dim=16,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=30,\n",
    "                                     name=\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "30e38891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_DISASTER():\n",
    "    inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    x = text_vectorizer(inputs)\n",
    "    x = embedding(x)\n",
    "    x = layers.LSTM(32)(x)\n",
    "    x = layers.Dense(2, activation = \"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ca4d8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "Model = model_DISASTER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "82a35285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ba1b6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "82d5baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 4s 959ms/step - loss: 0.6986 - accuracy: 0.3182 - val_loss: 0.6936 - val_accuracy: 0.4545\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6919 - accuracy: 0.6818 - val_loss: 0.6954 - val_accuracy: 0.4545\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6845 - accuracy: 0.6818 - val_loss: 0.6972 - val_accuracy: 0.4545\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6797 - accuracy: 0.6818 - val_loss: 0.6995 - val_accuracy: 0.4545\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6738 - accuracy: 0.6818 - val_loss: 0.7025 - val_accuracy: 0.4545\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6681 - accuracy: 0.6818 - val_loss: 0.7062 - val_accuracy: 0.4545\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6635 - accuracy: 0.6818 - val_loss: 0.7108 - val_accuracy: 0.4545\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6565 - accuracy: 0.6818 - val_loss: 0.7164 - val_accuracy: 0.4545\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6506 - accuracy: 0.6818 - val_loss: 0.7240 - val_accuracy: 0.4545\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6459 - accuracy: 0.6818 - val_loss: 0.7332 - val_accuracy: 0.4545\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6386 - accuracy: 0.6818 - val_loss: 0.7441 - val_accuracy: 0.4545\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6337 - accuracy: 0.6818 - val_loss: 0.7597 - val_accuracy: 0.4545\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6271 - accuracy: 0.6818 - val_loss: 0.7801 - val_accuracy: 0.4545\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6279 - accuracy: 0.6818 - val_loss: 0.8049 - val_accuracy: 0.4545\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8225 - val_accuracy: 0.4545\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6276 - accuracy: 0.6818 - val_loss: 0.8290 - val_accuracy: 0.4545\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6269 - accuracy: 0.6818 - val_loss: 0.8206 - val_accuracy: 0.4545\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6261 - accuracy: 0.6818 - val_loss: 0.8097 - val_accuracy: 0.4545\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6261 - accuracy: 0.6818 - val_loss: 0.8007 - val_accuracy: 0.4545\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.7960 - val_accuracy: 0.4545\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.7922 - val_accuracy: 0.4545\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6256 - accuracy: 0.6818 - val_loss: 0.7885 - val_accuracy: 0.4545\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.7820 - val_accuracy: 0.4545\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6265 - accuracy: 0.6818 - val_loss: 0.7769 - val_accuracy: 0.4545\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6265 - accuracy: 0.6818 - val_loss: 0.7752 - val_accuracy: 0.4545\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6267 - accuracy: 0.6818 - val_loss: 0.7734 - val_accuracy: 0.4545\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6269 - accuracy: 0.6818 - val_loss: 0.7717 - val_accuracy: 0.4545\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6273 - accuracy: 0.6818 - val_loss: 0.7699 - val_accuracy: 0.4545\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6274 - accuracy: 0.6818 - val_loss: 0.7669 - val_accuracy: 0.4545\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6278 - accuracy: 0.6818 - val_loss: 0.7638 - val_accuracy: 0.4545\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6288 - accuracy: 0.6818 - val_loss: 0.7622 - val_accuracy: 0.4545\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6288 - accuracy: 0.6818 - val_loss: 0.7634 - val_accuracy: 0.4545\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6286 - accuracy: 0.6818 - val_loss: 0.7661 - val_accuracy: 0.4545\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6278 - accuracy: 0.6818 - val_loss: 0.7706 - val_accuracy: 0.4545\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6266 - accuracy: 0.6818 - val_loss: 0.7791 - val_accuracy: 0.4545\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.7915 - val_accuracy: 0.4545\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6256 - accuracy: 0.6818 - val_loss: 0.8054 - val_accuracy: 0.4545\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6274 - accuracy: 0.6818 - val_loss: 0.8149 - val_accuracy: 0.4545\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6259 - accuracy: 0.6818 - val_loss: 0.8156 - val_accuracy: 0.4545\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6266 - accuracy: 0.6818 - val_loss: 0.8145 - val_accuracy: 0.4545\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8066 - val_accuracy: 0.4545\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6271 - accuracy: 0.6818 - val_loss: 0.8012 - val_accuracy: 0.4545\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.8025 - val_accuracy: 0.4545\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.8052 - val_accuracy: 0.4545\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6268 - accuracy: 0.6818 - val_loss: 0.8065 - val_accuracy: 0.4545\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8014 - val_accuracy: 0.4545\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.7984 - val_accuracy: 0.4545\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6255 - accuracy: 0.6818 - val_loss: 0.7963 - val_accuracy: 0.4545\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6256 - accuracy: 0.6818 - val_loss: 0.7968 - val_accuracy: 0.4545\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.8015 - val_accuracy: 0.4545\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.8099 - val_accuracy: 0.4545\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6261 - accuracy: 0.6818 - val_loss: 0.8151 - val_accuracy: 0.4545\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6258 - accuracy: 0.6818 - val_loss: 0.8161 - val_accuracy: 0.4545\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6258 - accuracy: 0.6818 - val_loss: 0.8176 - val_accuracy: 0.4545\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6259 - accuracy: 0.6818 - val_loss: 0.8193 - val_accuracy: 0.4545\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6260 - accuracy: 0.6818 - val_loss: 0.8212 - val_accuracy: 0.4545\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6262 - accuracy: 0.6818 - val_loss: 0.8222 - val_accuracy: 0.4545\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6263 - accuracy: 0.6818 - val_loss: 0.8207 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6261 - accuracy: 0.6818 - val_loss: 0.8190 - val_accuracy: 0.4545\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6261 - accuracy: 0.6818 - val_loss: 0.8158 - val_accuracy: 0.4545\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6258 - accuracy: 0.6818 - val_loss: 0.8140 - val_accuracy: 0.4545\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8120 - val_accuracy: 0.4545\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8073 - val_accuracy: 0.4545\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6252 - accuracy: 0.6818 - val_loss: 0.8045 - val_accuracy: 0.4545\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6257 - accuracy: 0.6818 - val_loss: 0.8024 - val_accuracy: 0.4545\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6256 - accuracy: 0.6818 - val_loss: 0.8025 - val_accuracy: 0.4545\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.7988 - val_accuracy: 0.4545\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6252 - accuracy: 0.6818 - val_loss: 0.7962 - val_accuracy: 0.4545\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6247 - accuracy: 0.6818 - val_loss: 0.7900 - val_accuracy: 0.4545\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6248 - accuracy: 0.6818 - val_loss: 0.7825 - val_accuracy: 0.4545\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.7761 - val_accuracy: 0.4545\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6270 - accuracy: 0.6818 - val_loss: 0.7718 - val_accuracy: 0.4545\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6268 - accuracy: 0.6818 - val_loss: 0.7709 - val_accuracy: 0.4545\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6268 - accuracy: 0.6818 - val_loss: 0.7694 - val_accuracy: 0.4545\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6270 - accuracy: 0.6818 - val_loss: 0.7698 - val_accuracy: 0.4545\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6267 - accuracy: 0.6818 - val_loss: 0.7725 - val_accuracy: 0.4545\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6263 - accuracy: 0.6818 - val_loss: 0.7772 - val_accuracy: 0.4545\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6253 - accuracy: 0.6818 - val_loss: 0.7829 - val_accuracy: 0.4545\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6254 - accuracy: 0.6818 - val_loss: 0.7897 - val_accuracy: 0.4545\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6243 - accuracy: 0.6818 - val_loss: 0.7947 - val_accuracy: 0.4545\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6238 - accuracy: 0.6818 - val_loss: 0.7994 - val_accuracy: 0.4545\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6232 - accuracy: 0.6818 - val_loss: 0.8043 - val_accuracy: 0.4545\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6233 - accuracy: 0.6818 - val_loss: 0.8099 - val_accuracy: 0.4545\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6231 - accuracy: 0.6818 - val_loss: 0.8072 - val_accuracy: 0.4545\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6208 - accuracy: 0.6818 - val_loss: 0.7965 - val_accuracy: 0.4545\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6196 - accuracy: 0.6818 - val_loss: 0.7879 - val_accuracy: 0.4545\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6186 - accuracy: 0.6818 - val_loss: 0.7821 - val_accuracy: 0.4545\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6151 - accuracy: 0.6818 - val_loss: 0.7797 - val_accuracy: 0.4545\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6080 - accuracy: 0.6818 - val_loss: 0.7738 - val_accuracy: 0.4545\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5919 - accuracy: 0.6818 - val_loss: 0.7643 - val_accuracy: 0.4545\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5701 - accuracy: 0.6818 - val_loss: 0.7621 - val_accuracy: 0.4545\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5336 - accuracy: 0.6818 - val_loss: 0.7737 - val_accuracy: 0.4545\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5220 - accuracy: 0.7500 - val_loss: 0.8259 - val_accuracy: 0.6364\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5361 - accuracy: 0.7727 - val_loss: 0.8570 - val_accuracy: 0.6364\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5276 - accuracy: 0.7727 - val_loss: 0.8238 - val_accuracy: 0.6364\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5105 - accuracy: 0.7727 - val_loss: 0.7565 - val_accuracy: 0.7273\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5289 - accuracy: 0.7500 - val_loss: 0.7449 - val_accuracy: 0.8182\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4929 - accuracy: 0.7727 - val_loss: 0.7598 - val_accuracy: 0.7273\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4923 - accuracy: 0.7955 - val_loss: 0.7301 - val_accuracy: 0.5455\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5221 - accuracy: 0.7045 - val_loss: 0.7128 - val_accuracy: 0.4545\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5224 - accuracy: 0.6818 - val_loss: 0.7246 - val_accuracy: 0.7273\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4916 - accuracy: 0.8182 - val_loss: 0.7051 - val_accuracy: 0.6364\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4758 - accuracy: 0.7727 - val_loss: 0.6844 - val_accuracy: 0.8182\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5097 - accuracy: 0.7727 - val_loss: 0.6718 - val_accuracy: 0.8182\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.6651 - val_accuracy: 0.7273\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4710 - accuracy: 0.8182 - val_loss: 0.7046 - val_accuracy: 0.7273\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4686 - accuracy: 0.8409 - val_loss: 0.7033 - val_accuracy: 0.7273\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4552 - accuracy: 0.8182 - val_loss: 0.6444 - val_accuracy: 0.7273\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4558 - accuracy: 0.8182 - val_loss: 0.6266 - val_accuracy: 0.7273\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4566 - accuracy: 0.8182 - val_loss: 0.6412 - val_accuracy: 0.7273\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4427 - accuracy: 0.8409 - val_loss: 0.6777 - val_accuracy: 0.7273\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4413 - accuracy: 0.8182 - val_loss: 0.6614 - val_accuracy: 0.7273\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4371 - accuracy: 0.8409 - val_loss: 0.6396 - val_accuracy: 0.7273\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4480 - accuracy: 0.8409 - val_loss: 0.6507 - val_accuracy: 0.7273\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4390 - accuracy: 0.8409 - val_loss: 0.6857 - val_accuracy: 0.7273\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4173 - accuracy: 0.8182 - val_loss: 0.7455 - val_accuracy: 0.7273\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4340 - accuracy: 0.8409 - val_loss: 0.7104 - val_accuracy: 0.7273\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4213 - accuracy: 0.8409 - val_loss: 0.6637 - val_accuracy: 0.7273\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4172 - accuracy: 0.8182 - val_loss: 0.6487 - val_accuracy: 0.7273\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4183 - accuracy: 0.8409 - val_loss: 0.6436 - val_accuracy: 0.7273\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4179 - accuracy: 0.8409 - val_loss: 0.6419 - val_accuracy: 0.7273\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4171 - accuracy: 0.8409 - val_loss: 0.6556 - val_accuracy: 0.7273\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4141 - accuracy: 0.8409 - val_loss: 0.6769 - val_accuracy: 0.7273\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4135 - accuracy: 0.8182 - val_loss: 0.6937 - val_accuracy: 0.7273\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4110 - accuracy: 0.8182 - val_loss: 0.6941 - val_accuracy: 0.7273\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4173 - accuracy: 0.8182 - val_loss: 0.6847 - val_accuracy: 0.7273\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4065 - accuracy: 0.8409 - val_loss: 0.6359 - val_accuracy: 0.7273\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4168 - accuracy: 0.8409 - val_loss: 0.5986 - val_accuracy: 0.7273\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4223 - accuracy: 0.8409 - val_loss: 0.5686 - val_accuracy: 0.7273\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4220 - accuracy: 0.8409 - val_loss: 0.5604 - val_accuracy: 0.7273\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4195 - accuracy: 0.8409 - val_loss: 0.5781 - val_accuracy: 0.7273\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4097 - accuracy: 0.8409 - val_loss: 0.6128 - val_accuracy: 0.7273\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4173 - accuracy: 0.8409 - val_loss: 0.6508 - val_accuracy: 0.7273\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4326 - accuracy: 0.8409 - val_loss: 0.6665 - val_accuracy: 0.7273\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4326 - accuracy: 0.8409 - val_loss: 0.6362 - val_accuracy: 0.7273\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4272 - accuracy: 0.8182 - val_loss: 0.5881 - val_accuracy: 0.7273\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4070 - accuracy: 0.8409 - val_loss: 0.5912 - val_accuracy: 0.7273\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4095 - accuracy: 0.8409 - val_loss: 0.6180 - val_accuracy: 0.7273\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4056 - accuracy: 0.8409 - val_loss: 0.6582 - val_accuracy: 0.7273\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4052 - accuracy: 0.8182 - val_loss: 0.7135 - val_accuracy: 0.7273\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4024 - accuracy: 0.8409 - val_loss: 0.7430 - val_accuracy: 0.7273\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4083 - accuracy: 0.8409 - val_loss: 0.7295 - val_accuracy: 0.7273\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4019 - accuracy: 0.8182 - val_loss: 0.6717 - val_accuracy: 0.7273\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4010 - accuracy: 0.8409 - val_loss: 0.6234 - val_accuracy: 0.7273\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4112 - accuracy: 0.8409 - val_loss: 0.6018 - val_accuracy: 0.7273\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4197 - accuracy: 0.8409 - val_loss: 0.6186 - val_accuracy: 0.7273\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4091 - accuracy: 0.8409 - val_loss: 0.6602 - val_accuracy: 0.7273\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4051 - accuracy: 0.8182 - val_loss: 0.6446 - val_accuracy: 0.7273\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4060 - accuracy: 0.8182 - val_loss: 0.6022 - val_accuracy: 0.7273\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3996 - accuracy: 0.8409 - val_loss: 0.5903 - val_accuracy: 0.7273\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3983 - accuracy: 0.8409 - val_loss: 0.5859 - val_accuracy: 0.7273\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3984 - accuracy: 0.8409 - val_loss: 0.5851 - val_accuracy: 0.7273\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3962 - accuracy: 0.8409 - val_loss: 0.5767 - val_accuracy: 0.7273\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3961 - accuracy: 0.8409 - val_loss: 0.5846 - val_accuracy: 0.7273\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3921 - accuracy: 0.8409 - val_loss: 0.6150 - val_accuracy: 0.7273\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4017 - accuracy: 0.8409 - val_loss: 0.6402 - val_accuracy: 0.7273\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3961 - accuracy: 0.8409 - val_loss: 0.5936 - val_accuracy: 0.7273\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3930 - accuracy: 0.8409 - val_loss: 0.5585 - val_accuracy: 0.7273\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3946 - accuracy: 0.8409 - val_loss: 0.5528 - val_accuracy: 0.7273\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3949 - accuracy: 0.8409 - val_loss: 0.5656 - val_accuracy: 0.7273\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3883 - accuracy: 0.8409 - val_loss: 0.5812 - val_accuracy: 0.7273\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3875 - accuracy: 0.8409 - val_loss: 0.6112 - val_accuracy: 0.7273\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3913 - accuracy: 0.8182 - val_loss: 0.6293 - val_accuracy: 0.7273\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3899 - accuracy: 0.8409 - val_loss: 0.6112 - val_accuracy: 0.7273\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3863 - accuracy: 0.8409 - val_loss: 0.5938 - val_accuracy: 0.7273\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3832 - accuracy: 0.8182 - val_loss: 0.5965 - val_accuracy: 0.7273\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3850 - accuracy: 0.8182 - val_loss: 0.6114 - val_accuracy: 0.7273\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3829 - accuracy: 0.8409 - val_loss: 0.6700 - val_accuracy: 0.7273\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3971 - accuracy: 0.8636 - val_loss: 0.6980 - val_accuracy: 0.7273\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4082 - accuracy: 0.8409 - val_loss: 0.5854 - val_accuracy: 0.7273\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3797 - accuracy: 0.8409 - val_loss: 0.5424 - val_accuracy: 0.7273\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3897 - accuracy: 0.8409 - val_loss: 0.5332 - val_accuracy: 0.7273\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3911 - accuracy: 0.8409 - val_loss: 0.5350 - val_accuracy: 0.7273\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3871 - accuracy: 0.8409 - val_loss: 0.5641 - val_accuracy: 0.7273\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3786 - accuracy: 0.8409 - val_loss: 0.5939 - val_accuracy: 0.7273\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3745 - accuracy: 0.8409 - val_loss: 0.6163 - val_accuracy: 0.7273\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3743 - accuracy: 0.8409 - val_loss: 0.6730 - val_accuracy: 0.7273\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3783 - accuracy: 0.8636 - val_loss: 0.7400 - val_accuracy: 0.5455\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4347 - accuracy: 0.7500 - val_loss: 0.6079 - val_accuracy: 0.7273\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3537 - accuracy: 0.8636 - val_loss: 0.5157 - val_accuracy: 0.7273\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4333 - accuracy: 0.8182 - val_loss: 0.5037 - val_accuracy: 0.9091\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4672 - accuracy: 0.7955 - val_loss: 0.4912 - val_accuracy: 0.9091\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4685 - accuracy: 0.8182 - val_loss: 0.4604 - val_accuracy: 0.9091\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4490 - accuracy: 0.8182 - val_loss: 0.4347 - val_accuracy: 0.8182\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4156 - accuracy: 0.8182 - val_loss: 0.4529 - val_accuracy: 0.7273\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3921 - accuracy: 0.8409 - val_loss: 0.5227 - val_accuracy: 0.7273\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3894 - accuracy: 0.8409 - val_loss: 0.6041 - val_accuracy: 0.7273\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3975 - accuracy: 0.8409 - val_loss: 0.6376 - val_accuracy: 0.7273\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4006 - accuracy: 0.8409 - val_loss: 0.6259 - val_accuracy: 0.7273\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3862 - accuracy: 0.8409 - val_loss: 0.6269 - val_accuracy: 0.7273\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3780 - accuracy: 0.8409 - val_loss: 0.6264 - val_accuracy: 0.7273\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3757 - accuracy: 0.8409 - val_loss: 0.6195 - val_accuracy: 0.7273\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3743 - accuracy: 0.8409 - val_loss: 0.6214 - val_accuracy: 0.7273\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3698 - accuracy: 0.8409 - val_loss: 0.6480 - val_accuracy: 0.7273\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3759 - accuracy: 0.8409 - val_loss: 0.6672 - val_accuracy: 0.7273\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3847 - accuracy: 0.8409 - val_loss: 0.6506 - val_accuracy: 0.7273\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3708 - accuracy: 0.8636 - val_loss: 0.6522 - val_accuracy: 0.7273\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3702 - accuracy: 0.8636 - val_loss: 0.6342 - val_accuracy: 0.7273\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3764 - accuracy: 0.8409 - val_loss: 0.6017 - val_accuracy: 0.7273\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3691 - accuracy: 0.8409 - val_loss: 0.5731 - val_accuracy: 0.7273\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3565 - accuracy: 0.8409 - val_loss: 0.5519 - val_accuracy: 0.7273\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3594 - accuracy: 0.8636 - val_loss: 0.5404 - val_accuracy: 0.7273\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3829 - accuracy: 0.8636 - val_loss: 0.5171 - val_accuracy: 0.7273\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3890 - accuracy: 0.8636 - val_loss: 0.4783 - val_accuracy: 0.7273\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3682 - accuracy: 0.8636 - val_loss: 0.4478 - val_accuracy: 0.7273\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3640 - accuracy: 0.8409 - val_loss: 0.4343 - val_accuracy: 0.7273\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3745 - accuracy: 0.8409 - val_loss: 0.4309 - val_accuracy: 0.7273\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3795 - accuracy: 0.8409 - val_loss: 0.4384 - val_accuracy: 0.7273\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3748 - accuracy: 0.8409 - val_loss: 0.4643 - val_accuracy: 0.7273\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3799 - accuracy: 0.8409 - val_loss: 0.4630 - val_accuracy: 0.7273\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3579 - accuracy: 0.8409 - val_loss: 0.4330 - val_accuracy: 0.7273\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3580 - accuracy: 0.8409 - val_loss: 0.4309 - val_accuracy: 0.9091\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3690 - accuracy: 0.8409 - val_loss: 0.4544 - val_accuracy: 0.9091\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3787 - accuracy: 0.8409 - val_loss: 0.4697 - val_accuracy: 0.9091\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3701 - accuracy: 0.8409 - val_loss: 0.4826 - val_accuracy: 0.7273\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3604 - accuracy: 0.8864 - val_loss: 0.5071 - val_accuracy: 0.7273\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3509 - accuracy: 0.8636 - val_loss: 0.5221 - val_accuracy: 0.7273\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3447 - accuracy: 0.8636 - val_loss: 0.5357 - val_accuracy: 0.7273\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3420 - accuracy: 0.8409 - val_loss: 0.5550 - val_accuracy: 0.7273\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3393 - accuracy: 0.8636 - val_loss: 0.5825 - val_accuracy: 0.7273\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3466 - accuracy: 0.8636 - val_loss: 0.5799 - val_accuracy: 0.7273\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3370 - accuracy: 0.8636 - val_loss: 0.5761 - val_accuracy: 0.7273\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3344 - accuracy: 0.8636 - val_loss: 0.5483 - val_accuracy: 0.7273\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3269 - accuracy: 0.8636 - val_loss: 0.5117 - val_accuracy: 0.7273\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3246 - accuracy: 0.8409 - val_loss: 0.4785 - val_accuracy: 0.7273\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3214 - accuracy: 0.8636 - val_loss: 0.4638 - val_accuracy: 0.7273\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3343 - accuracy: 0.8864 - val_loss: 0.4608 - val_accuracy: 0.7273\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3256 - accuracy: 0.8864 - val_loss: 0.4798 - val_accuracy: 0.7273\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3101 - accuracy: 0.8864 - val_loss: 0.5194 - val_accuracy: 0.7273\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3009 - accuracy: 0.8864 - val_loss: 0.5683 - val_accuracy: 0.7273\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3576 - accuracy: 0.7727 - val_loss: 0.5807 - val_accuracy: 0.7273\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4371 - accuracy: 0.8636 - val_loss: 0.4964 - val_accuracy: 0.9091\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5237 - accuracy: 0.8409 - val_loss: 0.4472 - val_accuracy: 0.9091\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5204 - accuracy: 0.7955 - val_loss: 0.3981 - val_accuracy: 0.8182\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4498 - accuracy: 0.7955 - val_loss: 0.3585 - val_accuracy: 0.9091\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3999 - accuracy: 0.8409 - val_loss: 0.3510 - val_accuracy: 0.9091\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3991 - accuracy: 0.8409 - val_loss: 0.3600 - val_accuracy: 0.9091\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4020 - accuracy: 0.8182 - val_loss: 0.3840 - val_accuracy: 0.7273\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4147 - accuracy: 0.8409 - val_loss: 0.4226 - val_accuracy: 0.7273\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4120 - accuracy: 0.8636 - val_loss: 0.4360 - val_accuracy: 0.7273\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3994 - accuracy: 0.8409 - val_loss: 0.4358 - val_accuracy: 0.7273\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3777 - accuracy: 0.8409 - val_loss: 0.4261 - val_accuracy: 0.7273\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3547 - accuracy: 0.8409 - val_loss: 0.4341 - val_accuracy: 0.7273\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3381 - accuracy: 0.8409 - val_loss: 0.4552 - val_accuracy: 0.7273\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3360 - accuracy: 0.8409 - val_loss: 0.4694 - val_accuracy: 0.7273\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3156 - accuracy: 0.8864 - val_loss: 0.4802 - val_accuracy: 0.7273\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3155 - accuracy: 0.8864 - val_loss: 0.5465 - val_accuracy: 0.6364\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3566 - accuracy: 0.8182 - val_loss: 0.5030 - val_accuracy: 0.8182\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3160 - accuracy: 0.8409 - val_loss: 0.5443 - val_accuracy: 0.8182\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3546 - accuracy: 0.8182 - val_loss: 0.5278 - val_accuracy: 0.8182\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3373 - accuracy: 0.8182 - val_loss: 0.4653 - val_accuracy: 0.8182\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2900 - accuracy: 0.8864 - val_loss: 0.4959 - val_accuracy: 0.5455\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3187 - accuracy: 0.8182 - val_loss: 0.4682 - val_accuracy: 0.7273\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3118 - accuracy: 0.8409 - val_loss: 0.4931 - val_accuracy: 0.7273\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3542 - accuracy: 0.8409 - val_loss: 0.4827 - val_accuracy: 0.7273\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3446 - accuracy: 0.8409 - val_loss: 0.4561 - val_accuracy: 0.7273\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3106 - accuracy: 0.8409 - val_loss: 0.4371 - val_accuracy: 0.7273\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3327 - accuracy: 0.7955 - val_loss: 0.3799 - val_accuracy: 0.7273\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2924 - accuracy: 0.9091 - val_loss: 0.3653 - val_accuracy: 0.9091\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3334 - accuracy: 0.8409 - val_loss: 0.3763 - val_accuracy: 0.9091\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3652 - accuracy: 0.8182 - val_loss: 0.3763 - val_accuracy: 0.8182\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3567 - accuracy: 0.8182 - val_loss: 0.3622 - val_accuracy: 0.9091\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3275 - accuracy: 0.8182 - val_loss: 0.3498 - val_accuracy: 0.9091\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3036 - accuracy: 0.8636 - val_loss: 0.3727 - val_accuracy: 0.7273\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3009 - accuracy: 0.9091 - val_loss: 0.4252 - val_accuracy: 0.7273\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2803 - accuracy: 0.8864 - val_loss: 0.4973 - val_accuracy: 0.7273\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2908 - accuracy: 0.8864 - val_loss: 0.5056 - val_accuracy: 0.7273\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3066 - accuracy: 0.8636 - val_loss: 0.4701 - val_accuracy: 0.7273\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2942 - accuracy: 0.8864 - val_loss: 0.3715 - val_accuracy: 0.7273\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2308 - accuracy: 0.9091 - val_loss: 0.4366 - val_accuracy: 0.8182\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3984 - accuracy: 0.7500 - val_loss: 0.3473 - val_accuracy: 0.8182\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3108 - accuracy: 0.8636 - val_loss: 0.4307 - val_accuracy: 0.8182\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3262 - accuracy: 0.8182 - val_loss: 0.3726 - val_accuracy: 0.8182\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3034 - accuracy: 0.8409 - val_loss: 0.3302 - val_accuracy: 0.8182\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2761 - accuracy: 0.8636 - val_loss: 0.3322 - val_accuracy: 0.8182\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2615 - accuracy: 0.9091 - val_loss: 0.3565 - val_accuracy: 0.7273\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2475 - accuracy: 0.9091 - val_loss: 0.4754 - val_accuracy: 0.7273\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2930 - accuracy: 0.8864 - val_loss: 0.5720 - val_accuracy: 0.7273\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3546 - accuracy: 0.8409 - val_loss: 0.5423 - val_accuracy: 0.7273\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2830 - accuracy: 0.8864 - val_loss: 0.4736 - val_accuracy: 0.6364\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3297 - accuracy: 0.7500 - val_loss: 0.4254 - val_accuracy: 0.6364\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3104 - accuracy: 0.7727 - val_loss: 0.3704 - val_accuracy: 0.7273\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2783 - accuracy: 0.8864 - val_loss: 0.3801 - val_accuracy: 0.7273\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2990 - accuracy: 0.8409 - val_loss: 0.3625 - val_accuracy: 0.7273\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2837 - accuracy: 0.8409 - val_loss: 0.3498 - val_accuracy: 0.7273\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2676 - accuracy: 0.8864 - val_loss: 0.3536 - val_accuracy: 0.7273\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2961 - accuracy: 0.8636 - val_loss: 0.3488 - val_accuracy: 0.7273\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2755 - accuracy: 0.8864 - val_loss: 0.3399 - val_accuracy: 0.7273\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2637 - accuracy: 0.8636 - val_loss: 0.3738 - val_accuracy: 0.8182\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2967 - accuracy: 0.8409 - val_loss: 0.3864 - val_accuracy: 0.7273\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2975 - accuracy: 0.8409 - val_loss: 0.3476 - val_accuracy: 0.7273\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2622 - accuracy: 0.8864 - val_loss: 0.3253 - val_accuracy: 0.8182\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2621 - accuracy: 0.8864 - val_loss: 0.3114 - val_accuracy: 0.8182\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2491 - accuracy: 0.8864 - val_loss: 0.3197 - val_accuracy: 0.7273\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2623 - accuracy: 0.8864 - val_loss: 0.2990 - val_accuracy: 0.7273\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2463 - accuracy: 0.9091 - val_loss: 0.2553 - val_accuracy: 0.8182\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2374 - accuracy: 0.9091 - val_loss: 0.2413 - val_accuracy: 0.9091\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2355 - accuracy: 0.9091 - val_loss: 0.2277 - val_accuracy: 0.9091\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2372 - accuracy: 0.8864 - val_loss: 0.2484 - val_accuracy: 0.8182\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2571 - accuracy: 0.9091 - val_loss: 0.2159 - val_accuracy: 0.9091\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2484 - accuracy: 0.9091 - val_loss: 0.2309 - val_accuracy: 0.9091\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2570 - accuracy: 0.9091 - val_loss: 0.2141 - val_accuracy: 0.9091\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2380 - accuracy: 0.9091 - val_loss: 0.3255 - val_accuracy: 0.6364\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3616 - accuracy: 0.7727 - val_loss: 0.2283 - val_accuracy: 0.8182\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2251 - accuracy: 0.9091 - val_loss: 0.2447 - val_accuracy: 0.8182\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2295 - accuracy: 0.9091 - val_loss: 0.2559 - val_accuracy: 0.8182\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2340 - accuracy: 0.9091 - val_loss: 0.2431 - val_accuracy: 0.9091\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2308 - accuracy: 0.9091 - val_loss: 0.2216 - val_accuracy: 0.9091\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2308 - accuracy: 0.8864 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2669 - accuracy: 0.9091 - val_loss: 0.2161 - val_accuracy: 0.9091\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2187 - accuracy: 0.9091 - val_loss: 0.3459 - val_accuracy: 0.9091\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3050 - accuracy: 0.8636 - val_loss: 0.3752 - val_accuracy: 0.8182\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2903 - accuracy: 0.8864 - val_loss: 0.2859 - val_accuracy: 0.7273\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2583 - accuracy: 0.8636 - val_loss: 0.2675 - val_accuracy: 0.9091\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2569 - accuracy: 0.8864 - val_loss: 0.2223 - val_accuracy: 0.9091\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2429 - accuracy: 0.9091 - val_loss: 0.2247 - val_accuracy: 0.9091\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2321 - accuracy: 0.9091 - val_loss: 0.2305 - val_accuracy: 0.9091\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2272 - accuracy: 0.9091 - val_loss: 0.2601 - val_accuracy: 0.9091\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2400 - accuracy: 0.8864 - val_loss: 0.2475 - val_accuracy: 0.9091\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2323 - accuracy: 0.9091 - val_loss: 0.2504 - val_accuracy: 0.9091\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2590 - accuracy: 0.9091 - val_loss: 0.2966 - val_accuracy: 0.9091\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2782 - accuracy: 0.8636 - val_loss: 0.2161 - val_accuracy: 0.9091\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2468 - accuracy: 0.8636 - val_loss: 0.2248 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2868 - accuracy: 0.8864 - val_loss: 0.2192 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2125 - accuracy: 0.9318 - val_loss: 0.3096 - val_accuracy: 0.8182\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2529 - accuracy: 0.9091 - val_loss: 0.3746 - val_accuracy: 0.8182\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2822 - accuracy: 0.9091 - val_loss: 0.3028 - val_accuracy: 0.9091\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2345 - accuracy: 0.9091 - val_loss: 0.2207 - val_accuracy: 0.9091\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2269 - accuracy: 0.8864 - val_loss: 0.2473 - val_accuracy: 0.8182\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2837 - accuracy: 0.7727 - val_loss: 0.2151 - val_accuracy: 0.9091\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2504 - accuracy: 0.8864 - val_loss: 0.2515 - val_accuracy: 0.9091\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2426 - accuracy: 0.8864 - val_loss: 0.2349 - val_accuracy: 0.9091\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2275 - accuracy: 0.8864 - val_loss: 0.2279 - val_accuracy: 0.9091\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2414 - accuracy: 0.9091 - val_loss: 0.2156 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2447 - accuracy: 0.8636 - val_loss: 0.1974 - val_accuracy: 0.9091\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2336 - accuracy: 0.8864 - val_loss: 0.1868 - val_accuracy: 0.9091\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2352 - accuracy: 0.8864 - val_loss: 0.1846 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2342 - accuracy: 0.8636 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2352 - accuracy: 0.9091 - val_loss: 0.2194 - val_accuracy: 0.9091\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2049 - accuracy: 0.9091 - val_loss: 0.3236 - val_accuracy: 0.9091\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2683 - accuracy: 0.9091 - val_loss: 0.3128 - val_accuracy: 0.9091\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2725 - accuracy: 0.9091 - val_loss: 0.1848 - val_accuracy: 0.9091\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2092 - accuracy: 0.9091 - val_loss: 0.2041 - val_accuracy: 0.8182\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2870 - accuracy: 0.7727 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2143 - accuracy: 0.9091 - val_loss: 0.2525 - val_accuracy: 0.9091\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2542 - accuracy: 0.9091 - val_loss: 0.2646 - val_accuracy: 0.9091\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2395 - accuracy: 0.9091 - val_loss: 0.1890 - val_accuracy: 0.9091\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2177 - accuracy: 0.8864 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2459 - accuracy: 0.8864 - val_loss: 0.1770 - val_accuracy: 0.9091\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2201 - accuracy: 0.8864 - val_loss: 0.2244 - val_accuracy: 0.9091\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2365 - accuracy: 0.8864 - val_loss: 0.2476 - val_accuracy: 0.9091\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2343 - accuracy: 0.9091 - val_loss: 0.2286 - val_accuracy: 0.9091\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2089 - accuracy: 0.9091 - val_loss: 0.2558 - val_accuracy: 0.9091\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2701 - accuracy: 0.8864 - val_loss: 0.1649 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2238 - accuracy: 0.8864 - val_loss: 0.4357 - val_accuracy: 0.8182\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2990 - accuracy: 0.8636 - val_loss: 1.1897 - val_accuracy: 0.5455\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3871 - accuracy: 0.8409 - val_loss: 1.3847 - val_accuracy: 0.5455\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4139 - accuracy: 0.8182 - val_loss: 1.2553 - val_accuracy: 0.5455\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3561 - accuracy: 0.8636 - val_loss: 1.0515 - val_accuracy: 0.6364\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3478 - accuracy: 0.8636 - val_loss: 0.8021 - val_accuracy: 0.6364\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2958 - accuracy: 0.8864 - val_loss: 0.5952 - val_accuracy: 0.7273\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2677 - accuracy: 0.8864 - val_loss: 0.5108 - val_accuracy: 0.6364\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2868 - accuracy: 0.8864 - val_loss: 0.4727 - val_accuracy: 0.6364\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2716 - accuracy: 0.8864 - val_loss: 0.4115 - val_accuracy: 0.6364\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2744 - accuracy: 0.8864 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2619 - accuracy: 0.9091 - val_loss: 0.4559 - val_accuracy: 0.7273\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2525 - accuracy: 0.9091 - val_loss: 0.4418 - val_accuracy: 0.7273\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2451 - accuracy: 0.9091 - val_loss: 0.4153 - val_accuracy: 0.8182\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2459 - accuracy: 0.9091 - val_loss: 0.4121 - val_accuracy: 0.8182\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2624 - accuracy: 0.9091 - val_loss: 0.4051 - val_accuracy: 0.7273\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2641 - accuracy: 0.9091 - val_loss: 0.4383 - val_accuracy: 0.7273\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2499 - accuracy: 0.9091 - val_loss: 0.3807 - val_accuracy: 0.7273\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2462 - accuracy: 0.9091 - val_loss: 0.3639 - val_accuracy: 0.8182\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2347 - accuracy: 0.8864 - val_loss: 0.3864 - val_accuracy: 0.7273\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2437 - accuracy: 0.8864 - val_loss: 0.4086 - val_accuracy: 0.7273\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2580 - accuracy: 0.8864 - val_loss: 0.3665 - val_accuracy: 0.7273\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2391 - accuracy: 0.9091 - val_loss: 0.3274 - val_accuracy: 0.8182\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2538 - accuracy: 0.9091 - val_loss: 0.3248 - val_accuracy: 0.8182\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2283 - accuracy: 0.9091 - val_loss: 0.3992 - val_accuracy: 0.7273\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2825 - accuracy: 0.9091 - val_loss: 0.4516 - val_accuracy: 0.7273\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2747 - accuracy: 0.9091 - val_loss: 0.3534 - val_accuracy: 0.7273\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2459 - accuracy: 0.9091 - val_loss: 0.3132 - val_accuracy: 0.8182\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2487 - accuracy: 0.9091 - val_loss: 0.3024 - val_accuracy: 0.8182\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2403 - accuracy: 0.9091 - val_loss: 0.3139 - val_accuracy: 0.7273\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2307 - accuracy: 0.9091 - val_loss: 0.3334 - val_accuracy: 0.7273\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2440 - accuracy: 0.9091 - val_loss: 0.3412 - val_accuracy: 0.7273\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2540 - accuracy: 0.9091 - val_loss: 0.3251 - val_accuracy: 0.7273\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2469 - accuracy: 0.9091 - val_loss: 0.2957 - val_accuracy: 0.7273\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2273 - accuracy: 0.9091 - val_loss: 0.2870 - val_accuracy: 0.7273\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2246 - accuracy: 0.9091 - val_loss: 0.2743 - val_accuracy: 0.7273\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2228 - accuracy: 0.9091 - val_loss: 0.2636 - val_accuracy: 0.8182\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2242 - accuracy: 0.9091 - val_loss: 0.2523 - val_accuracy: 0.8182\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2131 - accuracy: 0.9091 - val_loss: 0.2327 - val_accuracy: 0.9091\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2289 - accuracy: 0.9091 - val_loss: 0.2271 - val_accuracy: 0.8182\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2119 - accuracy: 0.9091 - val_loss: 0.2786 - val_accuracy: 0.9091\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2354 - accuracy: 0.9091 - val_loss: 0.2305 - val_accuracy: 0.9091\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1977 - accuracy: 0.9318 - val_loss: 0.2584 - val_accuracy: 0.8182\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2902 - accuracy: 0.7727 - val_loss: 0.2179 - val_accuracy: 0.9091\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2317 - accuracy: 0.9091 - val_loss: 0.3389 - val_accuracy: 0.9091\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2907 - accuracy: 0.8864 - val_loss: 0.3391 - val_accuracy: 0.9091\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2906 - accuracy: 0.8864 - val_loss: 0.2761 - val_accuracy: 0.9091\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2483 - accuracy: 0.9091 - val_loss: 0.2332 - val_accuracy: 0.9091\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2373 - accuracy: 0.8864 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2462 - accuracy: 0.8864 - val_loss: 0.2288 - val_accuracy: 0.9091\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2395 - accuracy: 0.9091 - val_loss: 0.2316 - val_accuracy: 0.9091\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2323 - accuracy: 0.9091 - val_loss: 0.2387 - val_accuracy: 0.9091\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2248 - accuracy: 0.9091 - val_loss: 0.2428 - val_accuracy: 0.9091\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2198 - accuracy: 0.9091 - val_loss: 0.2472 - val_accuracy: 0.9091\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2183 - accuracy: 0.9091 - val_loss: 0.2382 - val_accuracy: 0.9091\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2167 - accuracy: 0.9091 - val_loss: 0.2146 - val_accuracy: 0.9091\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2073 - accuracy: 0.9091 - val_loss: 0.1928 - val_accuracy: 0.9091\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2059 - accuracy: 0.8864 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2037 - accuracy: 0.8864 - val_loss: 0.1694 - val_accuracy: 0.9091\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1998 - accuracy: 0.8864 - val_loss: 0.1956 - val_accuracy: 0.9091\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2121 - accuracy: 0.9091 - val_loss: 0.1710 - val_accuracy: 0.9091\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2134 - accuracy: 0.9091 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1965 - accuracy: 0.9091 - val_loss: 0.1707 - val_accuracy: 0.9091\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2029 - accuracy: 0.9091 - val_loss: 0.1791 - val_accuracy: 0.9091\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2123 - accuracy: 0.9091 - val_loss: 0.1516 - val_accuracy: 0.9091\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.1969 - accuracy: 0.9091 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2078 - accuracy: 0.8864 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.1920 - accuracy: 0.9318 - val_loss: 0.2588 - val_accuracy: 0.9091\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2634 - accuracy: 0.9091 - val_loss: 0.3160 - val_accuracy: 0.9091\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2576 - accuracy: 0.9091 - val_loss: 0.1848 - val_accuracy: 0.9091\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2156 - accuracy: 0.9091 - val_loss: 0.2159 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2620 - accuracy: 0.8864 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2078 - accuracy: 0.9091 - val_loss: 0.2351 - val_accuracy: 0.9091\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2335 - accuracy: 0.9091 - val_loss: 0.2652 - val_accuracy: 0.9091\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2401 - accuracy: 0.9091 - val_loss: 0.2622 - val_accuracy: 0.9091\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2351 - accuracy: 0.9091 - val_loss: 0.2518 - val_accuracy: 0.8182\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2185 - accuracy: 0.9091 - val_loss: 0.2296 - val_accuracy: 0.9091\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2177 - accuracy: 0.9091 - val_loss: 0.2136 - val_accuracy: 0.9091\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2089 - accuracy: 0.9091 - val_loss: 0.2144 - val_accuracy: 0.9091\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2070 - accuracy: 0.9091 - val_loss: 0.2309 - val_accuracy: 0.9091\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2262 - accuracy: 0.9091 - val_loss: 0.2111 - val_accuracy: 0.9091\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2340 - accuracy: 0.9091 - val_loss: 0.1706 - val_accuracy: 0.9091\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1971 - accuracy: 0.9091 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2109 - accuracy: 0.9091 - val_loss: 0.2900 - val_accuracy: 0.9091\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2446 - accuracy: 0.9091 - val_loss: 0.1857 - val_accuracy: 0.9091\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2043 - accuracy: 0.9091 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2086 - accuracy: 0.8864 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2044 - accuracy: 0.9091 - val_loss: 0.1775 - val_accuracy: 0.9091\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1994 - accuracy: 0.9091 - val_loss: 0.2074 - val_accuracy: 0.9091\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2109 - accuracy: 0.9091 - val_loss: 0.2208 - val_accuracy: 0.9091\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2166 - accuracy: 0.9091 - val_loss: 0.2083 - val_accuracy: 0.9091\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2012 - accuracy: 0.9091 - val_loss: 0.1838 - val_accuracy: 0.9091\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1959 - accuracy: 0.9091 - val_loss: 0.1840 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2192 - accuracy: 0.8864 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2080 - accuracy: 0.9091 - val_loss: 0.1921 - val_accuracy: 0.9091\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2387 - accuracy: 0.9091 - val_loss: 0.2352 - val_accuracy: 0.9091\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2253 - accuracy: 0.9091 - val_loss: 0.1578 - val_accuracy: 0.9091\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.1910 - accuracy: 0.9318 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2497 - accuracy: 0.9091 - val_loss: 0.1605 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2163 - accuracy: 0.9091 - val_loss: 0.1755 - val_accuracy: 0.9091\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2023 - accuracy: 0.9091 - val_loss: 0.2306 - val_accuracy: 0.9091\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2242 - accuracy: 0.9091 - val_loss: 0.2149 - val_accuracy: 0.9091\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2036 - accuracy: 0.9091 - val_loss: 0.1795 - val_accuracy: 0.9091\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2032 - accuracy: 0.8864 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2185 - accuracy: 0.8864 - val_loss: 0.1703 - val_accuracy: 0.9091\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1988 - accuracy: 0.8864 - val_loss: 0.1852 - val_accuracy: 0.9091\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2059 - accuracy: 0.9091 - val_loss: 0.2079 - val_accuracy: 0.9091\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2165 - accuracy: 0.9091 - val_loss: 0.1894 - val_accuracy: 0.9091\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2017 - accuracy: 0.8864 - val_loss: 0.1669 - val_accuracy: 0.9091\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2010 - accuracy: 0.8864 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2071 - accuracy: 0.8864 - val_loss: 0.1599 - val_accuracy: 0.9091\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1998 - accuracy: 0.8864 - val_loss: 0.1926 - val_accuracy: 0.9091\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2058 - accuracy: 0.9091 - val_loss: 0.1922 - val_accuracy: 0.9091\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2053 - accuracy: 0.9091 - val_loss: 0.1827 - val_accuracy: 0.9091\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.1963 - accuracy: 0.9091 - val_loss: 0.1600 - val_accuracy: 0.9091\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.1901 - accuracy: 0.9091 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1938 - accuracy: 0.9091 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2098 - accuracy: 0.8864 - val_loss: 0.1276 - val_accuracy: 0.9091\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2125 - accuracy: 0.9091 - val_loss: 0.1737 - val_accuracy: 0.9091\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2174 - accuracy: 0.9091 - val_loss: 0.2315 - val_accuracy: 0.9091\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2572 - accuracy: 0.9091 - val_loss: 0.1428 - val_accuracy: 0.9091\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.1896 - accuracy: 0.9545 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2735 - accuracy: 0.8864 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2632 - accuracy: 0.8636 - val_loss: 0.1711 - val_accuracy: 0.9091\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2407 - accuracy: 0.8864 - val_loss: 0.2115 - val_accuracy: 0.9091\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3749 - accuracy: 0.8864 - val_loss: 0.3526 - val_accuracy: 0.8182\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3329 - accuracy: 0.8864 - val_loss: 1.1917 - val_accuracy: 0.7273\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3891 - accuracy: 0.8864 - val_loss: 0.7471 - val_accuracy: 0.7273\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3318 - accuracy: 0.8864 - val_loss: 0.3397 - val_accuracy: 0.8182\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3439 - accuracy: 0.8864 - val_loss: 0.2648 - val_accuracy: 0.8182\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3484 - accuracy: 0.8864 - val_loss: 0.2467 - val_accuracy: 0.9091\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3375 - accuracy: 0.9091 - val_loss: 0.2528 - val_accuracy: 0.9091\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3218 - accuracy: 0.8864 - val_loss: 0.2880 - val_accuracy: 0.8182\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3140 - accuracy: 0.8864 - val_loss: 0.3624 - val_accuracy: 0.7273\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3133 - accuracy: 0.8864 - val_loss: 0.5728 - val_accuracy: 0.7273\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3107 - accuracy: 0.8864 - val_loss: 0.8658 - val_accuracy: 0.7273\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2949 - accuracy: 0.8864 - val_loss: 0.5813 - val_accuracy: 0.7273\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2894 - accuracy: 0.8864 - val_loss: 0.3336 - val_accuracy: 0.7273\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2839 - accuracy: 0.8864 - val_loss: 0.2893 - val_accuracy: 0.8182\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2949 - accuracy: 0.8864 - val_loss: 0.2722 - val_accuracy: 0.8182\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2726 - accuracy: 0.8864 - val_loss: 0.2820 - val_accuracy: 0.9091\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3158 - accuracy: 0.8864 - val_loss: 0.2736 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2986 - accuracy: 0.8864 - val_loss: 0.2520 - val_accuracy: 0.9091\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2889 - accuracy: 0.8864 - val_loss: 0.2904 - val_accuracy: 0.9091\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3067 - accuracy: 0.8864 - val_loss: 0.2758 - val_accuracy: 0.9091\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3007 - accuracy: 0.8864 - val_loss: 0.2677 - val_accuracy: 0.9091\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2784 - accuracy: 0.8864 - val_loss: 0.2799 - val_accuracy: 0.9091\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2765 - accuracy: 0.8864 - val_loss: 0.2941 - val_accuracy: 0.8182\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2764 - accuracy: 0.8864 - val_loss: 0.3153 - val_accuracy: 0.8182\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2719 - accuracy: 0.8864 - val_loss: 0.3444 - val_accuracy: 0.7273\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2814 - accuracy: 0.8864 - val_loss: 0.3578 - val_accuracy: 0.7273\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2813 - accuracy: 0.8864 - val_loss: 0.3715 - val_accuracy: 0.7273\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2799 - accuracy: 0.8864 - val_loss: 0.4070 - val_accuracy: 0.7273\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2696 - accuracy: 0.8864 - val_loss: 0.4303 - val_accuracy: 0.7273\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2679 - accuracy: 0.8864 - val_loss: 0.4299 - val_accuracy: 0.7273\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2773 - accuracy: 0.8864 - val_loss: 0.4272 - val_accuracy: 0.7273\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2526 - accuracy: 0.9091 - val_loss: 0.5204 - val_accuracy: 0.8182\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3381 - accuracy: 0.8409 - val_loss: 0.4429 - val_accuracy: 0.8182\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2833 - accuracy: 0.8864 - val_loss: 0.3599 - val_accuracy: 0.8182\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3003 - accuracy: 0.8864 - val_loss: 0.4116 - val_accuracy: 0.8182\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3375 - accuracy: 0.8864 - val_loss: 0.3469 - val_accuracy: 0.8182\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2918 - accuracy: 0.8864 - val_loss: 0.3207 - val_accuracy: 0.9091\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2911 - accuracy: 0.8864 - val_loss: 0.3368 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3234 - accuracy: 0.8864 - val_loss: 0.3286 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3056 - accuracy: 0.9091 - val_loss: 0.3183 - val_accuracy: 0.9091\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2806 - accuracy: 0.8864 - val_loss: 0.3336 - val_accuracy: 0.9091\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2892 - accuracy: 0.8864 - val_loss: 0.3541 - val_accuracy: 0.9091\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3062 - accuracy: 0.8864 - val_loss: 0.3523 - val_accuracy: 0.8182\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2899 - accuracy: 0.8864 - val_loss: 0.3740 - val_accuracy: 0.7273\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.2659 - accuracy: 0.8864 - val_loss: 0.6759 - val_accuracy: 0.8182\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2896 - accuracy: 0.8864 - val_loss: 0.9282 - val_accuracy: 0.8182\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3036 - accuracy: 0.8864 - val_loss: 0.8035 - val_accuracy: 0.7273\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2710 - accuracy: 0.8864 - val_loss: 0.5568 - val_accuracy: 0.7273\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.2825 - accuracy: 0.8864 - val_loss: 0.4836 - val_accuracy: 0.7273\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2993 - accuracy: 0.8864 - val_loss: 0.3900 - val_accuracy: 0.7273\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2860 - accuracy: 0.8864 - val_loss: 0.3682 - val_accuracy: 0.8182\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2775 - accuracy: 0.8864 - val_loss: 0.4086 - val_accuracy: 0.8182\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3031 - accuracy: 0.8864 - val_loss: 0.4019 - val_accuracy: 0.8182\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2826 - accuracy: 0.9091 - val_loss: 0.3693 - val_accuracy: 0.7273\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2636 - accuracy: 0.8864 - val_loss: 0.4048 - val_accuracy: 0.7273\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2822 - accuracy: 0.8864 - val_loss: 0.4607 - val_accuracy: 0.7273\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3063 - accuracy: 0.8864 - val_loss: 0.5070 - val_accuracy: 0.7273\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3038 - accuracy: 0.8864 - val_loss: 0.5594 - val_accuracy: 0.7273\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2741 - accuracy: 0.8864 - val_loss: 0.7462 - val_accuracy: 0.7273\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.2730 - accuracy: 0.8864 - val_loss: 0.8347 - val_accuracy: 0.8182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [326]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Model_history \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1397\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1395\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[1;32m-> 1397\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1398\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1399\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:2086\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;124;03m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \n\u001b[0;32m   2069\u001b[0m \u001b[38;5;124;03mExamples:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2083\u001b[0m \n\u001b[0;32m   2084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[1;32m-> 2086\u001b[0m   \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\keras\\metrics\\base_metric.py:253\u001b[0m, in \u001b[0;36mMetric.reset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 253\u001b[0m   \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\keras\\backend.py:4028\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m   4027\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[1;32m-> 4028\u001b[0m     \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4030\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:912\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    910\u001b[0m   validate_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mis_fully_defined()\n\u001b[0;32m    911\u001b[0m   kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_shape\n\u001b[1;32m--> 912\u001b[0m assign_op \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39massign_variable_op(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, value_tensor, name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_value:\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(assign_op)\n",
      "File \u001b[1;32mD:\\code\\code\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:141\u001b[0m, in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    140\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAssignVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidate_shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    145\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Model_history = Model.fit(X_train,\n",
    "                          y_train,\n",
    "                          epochs=epochs,\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          verbose = 1,\n",
    "                         batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c9c4d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=int64, numpy=\n",
       "array([766,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0], dtype=int64)>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135917d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "87887f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e53a97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "44aee0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(text_vectorizer(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2730275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70552599, 0.29447401]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([text_vectorizer(\"c\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c7e9ab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([44, 40])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b807f7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31              sir kise ho aap\n",
       "5            namaste mai raj hu\n",
       "32              sir ho kise aap\n",
       "13                  aap kise ho\n",
       "19    bato ji kya chal raha hai\n",
       "49           bhai bolo sab kisa\n",
       "41                       pranam\n",
       "26        hello sir kise ho app\n",
       "43                  pranam bhai\n",
       "12               how you doing \n",
       "52                    hiya bhai\n",
       "Name: response, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190b273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
